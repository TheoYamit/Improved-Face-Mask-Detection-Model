{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# First dealing with all of the imports\nimport os\nimport cv2\nimport numpy as np\nfrom tensorflow import keras as keras\nfrom keras.utils import img_to_array\nfrom keras.utils import to_categorical\nfrom keras.applications.mobilenet_v2 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T01:55:40.131884Z","iopub.execute_input":"2023-08-19T01:55:40.132189Z","iopub.status.idle":"2023-08-19T01:56:21.031273Z","shell.execute_reply.started":"2023-08-19T01:55:40.132160Z","shell.execute_reply":"2023-08-19T01:56:21.030217Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"D0819 01:56:12.766574724      15 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0819 01:56:12.766610533      15 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0819 01:56:12.766613976      15 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0819 01:56:12.766616746      15 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0819 01:56:12.766619051      15 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0819 01:56:12.766621721      15 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0819 01:56:12.766624287      15 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0819 01:56:12.766626685      15 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0819 01:56:12.766629767      15 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0819 01:56:12.766632047      15 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0819 01:56:12.766634467      15 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0819 01:56:12.766636716      15 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0819 01:56:12.766639164      15 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0819 01:56:12.766641449      15 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0819 01:56:12.766859953      15 ev_epoll1_linux.cc:122]               grpc epoll fd: 65\nD0819 01:56:12.766871483      15 ev_posix.cc:144]                      Using polling engine: epoll1\nD0819 01:56:12.766891127      15 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0819 01:56:12.767299029      15 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0819 01:56:12.767316126      15 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0819 01:56:12.767320685      15 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0819 01:56:12.767324002      15 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0819 01:56:12.767326950      15 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0819 01:56:12.767330204      15 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0819 01:56:12.767337996      15 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0819 01:56:12.767355503      15 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0819 01:56:12.767386946      15 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0819 01:56:12.767401251      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0819 01:56:12.767405362      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0819 01:56:12.767408756      15 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0819 01:56:12.767415043      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0819 01:56:12.767418649      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0819 01:56:12.767421721      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0819 01:56:12.767424823      15 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0819 01:56:12.770360969      15 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0819 01:56:12.783617246     301 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0819 01:56:12.790703013     301 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-08-19T01:56:12.79068534+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading and Preprocessing the Dataset \nimport xml.etree.ElementTree as ElemTree\nfrom collections import OrderedDict\n# Images and labels list\nimages = []\nlabels = []\ndata = OrderedDict()\n\nannotation_path = '/kaggle/input/face-mask-detection/annotations'\nimages_path = '/kaggle/input/face-mask-detection/images'\n\n# Function to parse the xml file \ndef parse_xml(xml_file):\n    tree = ElemTree.parse(xml_file)\n    root = tree.getroot()\n\n    bounding_boxes = []\n    temp_labels = []\n\n    for object in root.findall('object'):\n        temp_labels.append(object[0].text)\n        xmin = int(object[5][0].text)\n        ymin = int(object[5][1].text)\n        xmax = int(object[5][2].text)\n        ymax = int(object[5][3].text)\n        bounding_boxes.append([xmin, ymin, xmax, ymax])\n\n    return bounding_boxes, temp_labels\n\n# Looping through the annotations file directory \nfor xml_file in os.listdir(annotation_path):\n    if xml_file.endswith(\".xml\"):\n        image_path = os.path.join(images_path, xml_file[:-4] + \".png\")\n        filename = xml_file[:-4] + \".png\"\n        xml_path = os.path.join(annotation_path, xml_file)\n\n        image = cv2.imread(image_path)\n        bounding_boxes, xml_labels = parse_xml(xml_path)\n        tuple = (image, bounding_boxes, xml_labels)\n            \n\n    data[filename] = tuple","metadata":{"execution":{"iopub.status.busy":"2023-08-19T01:56:47.218269Z","iopub.execute_input":"2023-08-19T01:56:47.219099Z","iopub.status.idle":"2023-08-19T01:57:09.597593Z","shell.execute_reply.started":"2023-08-19T01:56:47.219064Z","shell.execute_reply":"2023-08-19T01:57:09.596634Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n","output_type":"stream"}]},{"cell_type":"code","source":"data_pre_list = []\nlabels_pre_list = []\n\nfor key in data.keys():\n    image, boxes, image_labels = data[key]\n    for box, label in zip(boxes, image_labels):\n        data_pre_list.append((image, box))\n        labels_pre_list.append(label)\n\ntrain_data, val_data, train_labels, val_labels = train_test_split(data_pre_list, labels_pre_list, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T01:57:36.083013Z","iopub.execute_input":"2023-08-19T01:57:36.083379Z","iopub.status.idle":"2023-08-19T01:57:36.095772Z","shell.execute_reply.started":"2023-08-19T01:57:36.083348Z","shell.execute_reply":"2023-08-19T01:57:36.094966Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Encoding the labels (with mask, no mask, wearing a mask incorrectly)\n# lb = LabelBinarizer()\n# labels = lb.fit_transform(labels).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:16:59.747396Z","iopub.execute_input":"2023-08-17T20:16:59.747737Z","iopub.status.idle":"2023-08-17T20:16:59.759241Z","shell.execute_reply.started":"2023-08-17T20:16:59.747708Z","shell.execute_reply":"2023-08-17T20:16:59.758215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(images.shape)\n# print(labels.shape)\n# print(lb.classes_)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:16:59.760597Z","iopub.execute_input":"2023-08-17T20:16:59.761044Z","iopub.status.idle":"2023-08-17T20:16:59.771759Z","shell.execute_reply.started":"2023-08-17T20:16:59.76101Z","shell.execute_reply":"2023-08-17T20:16:59.770697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into training and testing sets\n# (train_images, test_images, train_labels, test_labels) = train_test_split(images, labels, test_size = 0.30, stratify=labels, random_state = 42)\n# Test size of 0.20 means that 20% of data is for the test, and the rest is for the training set. \n# Picked a ranom state for reproduciablity if needed.","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:16:59.774777Z","iopub.execute_input":"2023-08-17T20:16:59.775088Z","iopub.status.idle":"2023-08-17T20:17:01.390866Z","shell.execute_reply.started":"2023-08-17T20:16:59.775062Z","shell.execute_reply":"2023-08-17T20:17:01.389669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation step.\n# Not entirely needed but helps to increase the diversity of the dataset\n# data_aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:17:01.39228Z","iopub.execute_input":"2023-08-17T20:17:01.392586Z","iopub.status.idle":"2023-08-17T20:17:01.397771Z","shell.execute_reply.started":"2023-08-17T20:17:01.392559Z","shell.execute_reply":"2023-08-17T20:17:01.396661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data_gen = data_aug.flow(train_images, train_labels, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:17:01.398879Z","iopub.execute_input":"2023-08-17T20:17:01.399184Z","iopub.status.idle":"2023-08-17T20:17:01.408788Z","shell.execute_reply.started":"2023-08-17T20:17:01.399158Z","shell.execute_reply":"2023-08-17T20:17:01.407946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\n\ninput_size = (300, 300)\n\nle = LabelEncoder()\n\n# Fit the LabelEncoder with all the labels\nle.fit(train_labels)\nle.fit(val_labels)\n\ntrain_images = []\ntrain_label = []\n\nfor (image, box), label in zip(train_data, train_labels):\n\n    x, y, width, height = box\n\n    cropped_image = image[y:y+height, x: x+width]\n\n    resized_image = cv2.resize(cropped_image, input_size)\n    normalized_image = resized_image / 255.0\n\n    # Transform the label using the fitted LabelEncoder\n    encoded_label = le.transform([label])\n    one_hot_label = to_categorical(encoded_label, num_classes=3)\n\n    train_images.append(normalized_image)\n    train_label.append(one_hot_label[0])\n\ntrain_images = np.array(train_images)\ntrain_label = np.array(train_label)\n\neval_images = []\neval_label = []\n\nfor (image, box), label in zip(val_data, val_labels):\n\n    x, y, width, height = box\n\n    cropped_image = image[y:y+height, x: x+width]\n\n    resized_image = cv2.resize(cropped_image, input_size)\n    normalized_image = resized_image / 255.0\n\n    # Transform the label using the fitted LabelEncoder\n    encoded_label = le.transform([label])\n    one_hot_label = to_categorical(encoded_label, num_classes=3)\n\n    eval_images.append(normalized_image)\n    eval_label.append(one_hot_label[0])\n\neval_images = np.array(eval_images)\neval_label = np.array(eval_label)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T01:58:19.607437Z","iopub.execute_input":"2023-08-19T01:58:19.608275Z","iopub.status.idle":"2023-08-19T01:58:31.126478Z","shell.execute_reply.started":"2023-08-19T01:58:19.608239Z","shell.execute_reply":"2023-08-19T01:58:31.125577Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(val_labels)\nfor item in eval_label:\n    print(item)\n\nprint(le.classes_)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T01:59:37.591889Z","iopub.execute_input":"2023-08-19T01:59:37.592273Z","iopub.status.idle":"2023-08-19T01:59:37.690337Z","shell.execute_reply.started":"2023-08-19T01:59:37.592244Z","shell.execute_reply":"2023-08-19T01:59:37.689304Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'without_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'mask_weared_incorrect', 'without_mask', 'without_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'mask_weared_incorrect', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'mask_weared_incorrect', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'without_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'with_mask', 'without_mask']\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[1. 0. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[1. 0. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 1. 0.]\n[0. 0. 1.]\n['mask_weared_incorrect' 'with_mask' 'without_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nprint('TPU Cluster Spec:', tpu.cluster_spec())\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T02:00:42.304004Z","iopub.execute_input":"2023-08-19T02:00:42.304436Z","iopub.status.idle":"2023-08-19T02:00:42.309744Z","shell.execute_reply.started":"2023-08-19T02:00:42.304403Z","shell.execute_reply":"2023-08-19T02:00:42.308895Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"TPU Cluster Spec: ClusterSpec({})\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications import InceptionV3\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\nfrom keras.optimizers import Adam\nfrom keras.losses import categorical_crossentropy\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n\nwith tpu_strategy.scope():\n\n    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(300, 300, 3))\n\n    # Freeze base model layers\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    # Add custom layers on top\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x) \n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    predictions = Dense(3, activation='softmax')(x)\n\n    # Create full model \n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    # Compile model\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss=categorical_crossentropy,\n                  metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T02:06:17.628524Z","iopub.execute_input":"2023-08-19T02:06:17.629463Z","iopub.status.idle":"2023-08-19T02:06:54.329456Z","shell.execute_reply.started":"2023-08-19T02:06:17.629420Z","shell.execute_reply":"2023-08-19T02:06:54.328203Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\nimport math\n# Compile model\n\n# Step decay schedule  \ndef step_decay(epoch):\n  initial_lrate = 0.0001\n  drop = 0.5\n  epochs_drop = 10.0\n  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n  return lrate\n\n# Learning rate scheduler callback  \nlr_scheduler = LearningRateScheduler(step_decay)\n\nmodel.fit(\n  train_images,\n  train_label, \n  epochs=50,\n  batch_size=32,\n  validation_data=(eval_images, eval_label),\n  callbacks=[lr_scheduler]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T02:14:27.385057Z","iopub.execute_input":"2023-08-19T02:14:27.386100Z","iopub.status.idle":"2023-08-19T02:16:15.045480Z","shell.execute_reply.started":"2023-08-19T02:14:27.386059Z","shell.execute_reply":"2023-08-19T02:16:15.044216Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/20\n102/102 [==============================] - 7s 69ms/step - loss: 0.1872 - accuracy: 0.9306 - val_loss: 0.6743 - val_accuracy: 0.8123 - lr: 1.0000e-04\nEpoch 2/20\n102/102 [==============================] - 5s 46ms/step - loss: 0.1907 - accuracy: 0.9257 - val_loss: 0.6573 - val_accuracy: 0.8000 - lr: 1.0000e-04\nEpoch 3/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.1762 - accuracy: 0.9343 - val_loss: 0.6722 - val_accuracy: 0.8037 - lr: 1.0000e-04\nEpoch 4/20\n102/102 [==============================] - 5s 46ms/step - loss: 0.1455 - accuracy: 0.9521 - val_loss: 0.7216 - val_accuracy: 0.8196 - lr: 1.0000e-04\nEpoch 5/20\n102/102 [==============================] - 5s 46ms/step - loss: 0.1348 - accuracy: 0.9493 - val_loss: 0.7919 - val_accuracy: 0.8160 - lr: 1.0000e-04\nEpoch 6/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.1265 - accuracy: 0.9539 - val_loss: 0.8224 - val_accuracy: 0.8123 - lr: 1.0000e-04\nEpoch 7/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.1119 - accuracy: 0.9607 - val_loss: 0.7983 - val_accuracy: 0.8160 - lr: 1.0000e-04\nEpoch 8/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.1007 - accuracy: 0.9675 - val_loss: 0.7497 - val_accuracy: 0.7755 - lr: 1.0000e-04\nEpoch 9/20\n102/102 [==============================] - 5s 48ms/step - loss: 0.1069 - accuracy: 0.9671 - val_loss: 0.7879 - val_accuracy: 0.8012 - lr: 1.0000e-04\nEpoch 10/20\n102/102 [==============================] - 5s 48ms/step - loss: 0.0789 - accuracy: 0.9785 - val_loss: 0.7791 - val_accuracy: 0.8086 - lr: 5.0000e-05\nEpoch 11/20\n102/102 [==============================] - 5s 46ms/step - loss: 0.0637 - accuracy: 0.9834 - val_loss: 0.8604 - val_accuracy: 0.8061 - lr: 5.0000e-05\nEpoch 12/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.0524 - accuracy: 0.9856 - val_loss: 0.8937 - val_accuracy: 0.8172 - lr: 5.0000e-05\nEpoch 13/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.0497 - accuracy: 0.9880 - val_loss: 0.9684 - val_accuracy: 0.8110 - lr: 5.0000e-05\nEpoch 14/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.0437 - accuracy: 0.9883 - val_loss: 1.0076 - val_accuracy: 0.8172 - lr: 5.0000e-05\nEpoch 15/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.0465 - accuracy: 0.9886 - val_loss: 0.8717 - val_accuracy: 0.8037 - lr: 5.0000e-05\nEpoch 16/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.0416 - accuracy: 0.9908 - val_loss: 0.8826 - val_accuracy: 0.8025 - lr: 5.0000e-05\nEpoch 17/20\n102/102 [==============================] - 5s 47ms/step - loss: 0.0406 - accuracy: 0.9902 - val_loss: 0.9346 - val_accuracy: 0.8209 - lr: 5.0000e-05\nEpoch 18/20\n102/102 [==============================] - 5s 46ms/step - loss: 0.0374 - accuracy: 0.9920 - val_loss: 0.9784 - val_accuracy: 0.8074 - lr: 5.0000e-05\nEpoch 19/20\n102/102 [==============================] - 5s 46ms/step - loss: 0.0376 - accuracy: 0.9908 - val_loss: 1.0202 - val_accuracy: 0.8110 - lr: 5.0000e-05\nEpoch 20/20\n102/102 [==============================] - 5s 45ms/step - loss: 0.0342 - accuracy: 0.9932 - val_loss: 0.9515 - val_accuracy: 0.8049 - lr: 2.5000e-05\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x780cb0261e80>"},"metadata":{}}]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(train_images, train_label)\nprint('Test accuracy:', test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T02:18:49.224377Z","iopub.execute_input":"2023-08-19T02:18:49.224799Z","iopub.status.idle":"2023-08-19T02:19:01.726906Z","shell.execute_reply.started":"2023-08-19T02:18:49.224762Z","shell.execute_reply":"2023-08-19T02:19:01.725664Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 4s 33ms/step - loss: 0.0070 - accuracy: 1.0000\nTest accuracy: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('modelImproved')","metadata":{"execution":{"iopub.status.busy":"2023-08-19T02:24:59.973669Z","iopub.execute_input":"2023-08-19T02:24:59.974375Z","iopub.status.idle":"2023-08-19T02:25:37.327507Z","shell.execute_reply.started":"2023-08-19T02:24:59.974338Z","shell.execute_reply":"2023-08-19T02:25:37.326200Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: modelImproved/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: modelImproved/assets\n","output_type":"stream"}]}]}